{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1 (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если разбить поисковые запросы пользователей в РФ по тематикам, то можно выделить несколько кластеров, запросы в которых имеют похожий смысл или тему. В файле `searches.csv` - 6 временных рядов, соответствующих кластерам: \n",
    "\n",
    "    1. Коронавирус\n",
    "    2. Отели за границей\n",
    "    3. Школьные задания\n",
    "    4. Подарки и поздравления\n",
    "    5. Спортивные события\n",
    "    6. Музыка\n",
    "\n",
    "Определите, какой временной ряд относится к какому кластеру.\n",
    "\n",
    "Дайте ответ для всех кластеров в формате \"кластерX - `<название>`, потому что ... (ваши наблюдения и выводы на основе временного ряда)\".\n",
    "\n",
    "Ответы без обоснования не будут приняты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a5f73520e9d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprophet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prophet'"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "searches_df = pd.read_csv('searches.csv', parse_dates=['ds'])\n",
    "searches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "data = pd.read_csv('searches.csv')\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "monthly_data = data.groupby(data['ds'].dt.to_period('M')).sum()\n",
    "monthly_data.index = monthly_data.index.astype(str)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for column in monthly_data.columns:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=monthly_data.index,\n",
    "        y=monthly_data[column],\n",
    "        name=f'Кластер {column}',\n",
    "        mode='lines'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='График суммы запросов по кластерам',\n",
    "    xaxis_title='Месяц',\n",
    "    yaxis_title='Сумма запросов'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "кластер1 - Спортивные события - методом исключения)\n",
    "\n",
    "кластер2 - Подарки и поздравления, тк количество запросов растет достигает пика каждый декабрь и февраль-март\n",
    "\n",
    "кластер3 - Музыка, тк количество запросов имеет восходящий тренд на всех данных, и из всех кластеров музыка меньше всего подвержена внешним изменениям\n",
    "\n",
    "калстер4 - Коронавирус, тк виден резкий рост количества запросов с января 2020-го \n",
    "\n",
    "калстер5 - Отели за границей, тк по сравнению с остальными кластерами имеет наименьшее количество запросов на протяжении всего времени, и после января 2020-го виден резкий спад (связано с коронавирусом)\n",
    "\n",
    "калстер6 - Школьные задания, тк количество запросов достигает минимумов каждое лето, а так же был резкий рост в апреле 2020, когда школьников закрыли на дистант"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Задача\n",
    "\n",
    "Вам дана небольшая выборка поисковых запросов, связанных с поиском работм. Запросы разбиты на подкатегории 1, 2, 3, 4, 5, 6, 7 и 8.\n",
    "Вам нужно сделать подневный прогноз **суммы** поисковых запросов с учётом трендов, сезонности, праздников и аномалий. При этом нужно продемонстрировать качество модели.\n",
    "\n",
    "Представьте, что сегодня 1 июля 2021 года, и вам нужно спрогнозировать количество запросов до конца 2021 года. \n",
    "\n",
    "Прогноз можно строить в Excel, Jupyter Notebook или другими знакомыми инструментами. Главное, чтобы расчёт мог воспроизвести другой человек.\n",
    "\n",
    "## Данные\n",
    "\n",
    "\n",
    "\n",
    "Для того, чтобы не только сделать прогноз, но и проверить качество модели, данные разбиты на три файла:\n",
    "\n",
    "`train.csv` - обучающая выборка с 2017-01-01 по 2020-12-31\n",
    "\n",
    "`test.csv` - тестовая выборка с 2021-01-01 по 2021-06-30\n",
    "\n",
    "`val.csv` - валидационная выборка с 2021-07-01 по 2021-12-31. **Для чистоты эксперимента не смотрите его пока что, это данные о будущем, которое хотим предсказать.**\n",
    "\n",
    "Их назначение будет объяснено позже.\n",
    "\n",
    "## Оценка качества\n",
    "\n",
    "Для оценки качества прогнозных моделей проведём эксперимент: скроем от модели часть известных нам данных, построим прогноз, а затем проверим, насколько хорошо он попадает в факт.\n",
    "\n",
    "Для оценки качества моделей будем использовать метрику [MAPE](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error) по дням: $\\text{MAPE} = 100\\% \\cdot \\dfrac{1}{n}\\sum_{i=1}^n  \\left|\\dfrac{факт_i - прогноз_i}{факт_i}\\right| $\n",
    "\n",
    "Например, если нужно рассчитать MAPE за первые 6 месяцев 2021 года (181 день), получим формулу $\\text{MAPE} = 100\\% \\cdot \\dfrac{1}{181}\\sum_{i=1}^{181}  \\left|\\dfrac{факт_i - прогноз_i}{факт_i}\\right| $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример функции MAPE, которая принимает на вход два списка с значениями\n",
    "def mape(fact_list, forecast_list):\n",
    "    errors = []\n",
    "    \n",
    "    for f, p in zip(fact_list, forecast_list):\n",
    "        e = abs((f - p) / f)\n",
    "        errors.append(e)\n",
    "\n",
    "    return 100.0 * sum(errors) / len(errors)\n",
    "\n",
    "mape([1, 2, 3, 4], [0.5, 1.5, 3, 4.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Базовый прогноз (1 балл)\n",
    "1. Откройте обучающую выборку из файла `train.csv` в Excel или загрузите в pandas DataFrame. Модели должны обучаться только на ней\n",
    "2. Постройте график временного ряда суммы поисковых запросов\n",
    "3. Постройте прогноз этого ряда до конца 2021 года любым удобным вам способом (например, взяв код или формулу из лекции) **без** очистки данных, подбора параметров модели, учёта праздников и пр.\n",
    "4. Прочитайте тестовые данные из файла `test.csv` и посчитайте ошибку прогноза (MAPE) на данных за первое полугодие 2021 года. Назовём это значение ошибки `mape1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', parse_dates=['ds'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# временной ряд суммы всех поисковых запросов (факт)\n",
    "train_sum_df =\n",
    "\n",
    "# постройте график суммарного временного ряда\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте прогноз этого суммарного ряда\n",
    "forecast_df_1 =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', parse_dates=['ds'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сумма всех поисков по дням из тестовой выборки\n",
    "test_sum_df =\n",
    "\n",
    "# посчитайте ошибку\n",
    "\n",
    "mape1 ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Декомпозиция (1 балл) \n",
    "\n",
    "Давайте проверим, получится ли модель точнее, если мы спрогнозируем сначала поиски по категориям, а затем суммируем.\n",
    "\n",
    "5. Посмотрите категории поисковых запросов и определите, стоит ли все временные ряды прогнозировать независимо, или часть из них стоит сгруппировать в более крупные сущности (например, из 8 временных рядов можно получить 4). Почему?\n",
    "6. Постройте прогнозы по исходным или сгруппированным временным рядам (так же **без** предобработки данных), посчитайте MAPE для суммы всех поисков. Назовём её `mape2`\n",
    "\n",
    "Задание считается выполненным, если у вас есть прогноз, есть **минимум 2 группы** запросов и вы **объяснили**, почему объединили данные именно так (если объединяли) или почему не стали объединять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгруппируйте категории запросов, если нужно. Почему именно так?\n",
    "train_df ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте прогноз по категориям\n",
    "forecast_df_2 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитайте ошибку по данным из test_sum_df\n",
    "\n",
    "mape2 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Улучшение модели (1 балл)\n",
    "\n",
    "7. Для каждой группы из предыдущего задания постройте графики с фактом (train + test) и прогнозом, визуально оцените качество прогноза \n",
    "8. Найдите недостатки, очистите временные ряды от аномалий или обновите параметры модели. Учтите праздники, если позволяет модель. Увеличить точность может использование не-статистического метода для какого-либо из рядов\n",
    "9. Сделайте прогноз и замерьте качество на суммарных поисках, назовите ошибку `mape3`\n",
    "\n",
    "Задание считается выполненным, если вы получили `mape3 < mape2` и `mape3 < mape1`, а прогноз №3 на весь 2021 год выглядит визуально адекватным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы сравнить каждую группу с тестовой выборкой, нужно так же сгруппировать данные в ней\n",
    "test_df = \n",
    "\n",
    "# факт для графиков\n",
    "train_and_test_df = pd.concat([test_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте прогноз по очищенным категориям запросов\n",
    "\n",
    "forecast_df_3 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитайте ошибку по данным из test_sum_df\n",
    "\n",
    "mape3 ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Валидация модели (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы обучали модель на обучающей выборке (train) и корректировали модель, основываясь на ошибке на тестовой выборке (test). Если при этом не оценивать прогноз визуально, модель может \"[переобучиться](https://neerc.ifmo.ru/wiki/index.php?title=Переобучение)\". В этом случае она будет хорошо предсказывать первое полугодие 2021, а другие периоды - плохо.\n",
    "\n",
    "Давайте проверим, смогла ли модель понять общие зависимости в данных или переобучилась. Для этого нужно посчитать ошибку на `val.csv` (2021-06-01 - 2021-12-31) для всех моделей.\n",
    "\n",
    "Задание считается выполненным, если корректно посчитана ошибка на валидационной выборке и построен итоговый график с фактом и прогнозами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('val.csv', parse_dates=['ds'])\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сумма всех рядов\n",
    "val_sum_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитайте ошибку на второе полугодие 2021 года для всех прогнозов\n",
    "\n",
    "val_error_1 =            # изначальный прогноз суммы\n",
    "val_error_2 =            # прогноз, разбитый на подкатегории\n",
    "val_error_3 =            # прогноз, разбитый на подкатегории и очищенный от аномалий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно ошибка на валидационной выборке больше, чем на тестовой, это нормально. Однако, если она **гораздо** (например, в разы) больше ошибки на тестовой выборке, модель переобучилась.\n",
    "\n",
    "Если ошибка получилась большой, это не критично: у нас не было цели создать идеальный прогноз. Основными критериями при оценивании домашнего задания будут методологически верный подход к построению и визуальная адекватность полученного прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте при приложите график суммы поисков с фактом (train + test + val) и всеми прогнозами\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
